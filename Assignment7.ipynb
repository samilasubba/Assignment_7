{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing no. of raw text data \n",
    "\n",
    "filename = \"Shakespear\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()\n",
    "raw_text=raw_text[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_chars  # reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99900"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(dataX)\n",
    "X = np.reshape(x, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0703 09:42:28.350209 140416091383616 deprecation_wrapper.py:119] From /home/samila/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0703 09:42:28.618176 140416091383616 deprecation_wrapper.py:119] From /home/samila/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0703 09:42:28.664663 140416091383616 deprecation_wrapper.py:119] From /home/samila/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0703 09:42:29.655491 140416091383616 deprecation_wrapper.py:119] From /home/samila/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0703 09:42:29.661664 140416091383616 deprecation.py:506] From /home/samila/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0703 09:42:29.850257 140416091383616 deprecation_wrapper.py:119] From /home/samila/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0703 09:42:29.872326 140416091383616 deprecation_wrapper.py:119] From /home/samila/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model using keras\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining weight files\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0703 09:42:42.500273 140416091383616 deprecation.py:323] From /home/samila/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "99900/99900 [==============================] - 572s 6ms/step - loss: 2.9672\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.96724, saving model to weights-improvement-01-2.9672.hdf5\n",
      "Epoch 2/20\n",
      "99900/99900 [==============================] - 550s 6ms/step - loss: 2.6259\n",
      "\n",
      "Epoch 00002: loss improved from 2.96724 to 2.62593, saving model to weights-improvement-02-2.6259.hdf5\n",
      "Epoch 3/20\n",
      "99900/99900 [==============================] - 545s 5ms/step - loss: 2.4456\n",
      "\n",
      "Epoch 00003: loss improved from 2.62593 to 2.44558, saving model to weights-improvement-03-2.4456.hdf5\n",
      "Epoch 4/20\n",
      "99900/99900 [==============================] - 1089s 11ms/step - loss: 2.3261\n",
      "\n",
      "Epoch 00004: loss improved from 2.44558 to 2.32612, saving model to weights-improvement-04-2.3261.hdf5\n",
      "Epoch 5/20\n",
      "99900/99900 [==============================] - 614s 6ms/step - loss: 2.2324\n",
      "\n",
      "Epoch 00005: loss improved from 2.32612 to 2.23240, saving model to weights-improvement-05-2.2324.hdf5\n",
      "Epoch 6/20\n",
      "99900/99900 [==============================] - 597s 6ms/step - loss: 2.1561\n",
      "\n",
      "Epoch 00006: loss improved from 2.23240 to 2.15611, saving model to weights-improvement-06-2.1561.hdf5\n",
      "Epoch 7/20\n",
      "99900/99900 [==============================] - 592s 6ms/step - loss: 2.0956\n",
      "\n",
      "Epoch 00007: loss improved from 2.15611 to 2.09563, saving model to weights-improvement-07-2.0956.hdf5\n",
      "Epoch 8/20\n",
      "99900/99900 [==============================] - 604s 6ms/step - loss: 2.0431\n",
      "\n",
      "Epoch 00008: loss improved from 2.09563 to 2.04307, saving model to weights-improvement-08-2.0431.hdf5\n",
      "Epoch 9/20\n",
      "99900/99900 [==============================] - 600s 6ms/step - loss: 1.9972\n",
      "\n",
      "Epoch 00009: loss improved from 2.04307 to 1.99716, saving model to weights-improvement-09-1.9972.hdf5\n",
      "Epoch 10/20\n",
      "99900/99900 [==============================] - 625s 6ms/step - loss: 1.9535\n",
      "\n",
      "Epoch 00010: loss improved from 1.99716 to 1.95350, saving model to weights-improvement-10-1.9535.hdf5\n",
      "Epoch 11/20\n",
      "99900/99900 [==============================] - 589s 6ms/step - loss: 1.9115\n",
      "\n",
      "Epoch 00011: loss improved from 1.95350 to 1.91145, saving model to weights-improvement-11-1.9115.hdf5\n",
      "Epoch 12/20\n",
      "99900/99900 [==============================] - 579s 6ms/step - loss: 1.8787\n",
      "\n",
      "Epoch 00012: loss improved from 1.91145 to 1.87872, saving model to weights-improvement-12-1.8787.hdf5\n",
      "Epoch 13/20\n",
      "99900/99900 [==============================] - 563s 6ms/step - loss: 1.8405\n",
      "\n",
      "Epoch 00013: loss improved from 1.87872 to 1.84054, saving model to weights-improvement-13-1.8405.hdf5\n",
      "Epoch 14/20\n",
      "99900/99900 [==============================] - 555s 6ms/step - loss: 1.8101\n",
      "\n",
      "Epoch 00014: loss improved from 1.84054 to 1.81010, saving model to weights-improvement-14-1.8101.hdf5\n",
      "Epoch 15/20\n",
      "99900/99900 [==============================] - 588s 6ms/step - loss: 1.7770\n",
      "\n",
      "Epoch 00015: loss improved from 1.81010 to 1.77704, saving model to weights-improvement-15-1.7770.hdf5\n",
      "Epoch 16/20\n",
      "99900/99900 [==============================] - 559s 6ms/step - loss: 1.7468\n",
      "\n",
      "Epoch 00016: loss improved from 1.77704 to 1.74677, saving model to weights-improvement-16-1.7468.hdf5\n",
      "Epoch 17/20\n",
      "99900/99900 [==============================] - 553s 6ms/step - loss: 1.7172\n",
      "\n",
      "Epoch 00017: loss improved from 1.74677 to 1.71716, saving model to weights-improvement-17-1.7172.hdf5\n",
      "Epoch 18/20\n",
      "99900/99900 [==============================] - 552s 6ms/step - loss: 1.6896\n",
      "\n",
      "Epoch 00018: loss improved from 1.71716 to 1.68961, saving model to weights-improvement-18-1.6896.hdf5\n",
      "Epoch 19/20\n",
      "99900/99900 [==============================] - 553s 6ms/step - loss: 1.6632\n",
      "\n",
      "Epoch 00019: loss improved from 1.68961 to 1.66319, saving model to weights-improvement-19-1.6632.hdf5\n",
      "Epoch 20/20\n",
      "99900/99900 [==============================] - 555s 6ms/step - loss: 1.6406\n",
      "\n",
      "Epoch 00020: loss improved from 1.66319 to 1.64059, saving model to weights-improvement-20-1.6406.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb4e98c64e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating tex with LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-20-1.6406.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'start = np.random.randint(0, len(dataX)-1)\\npattern = dataX[start]\\n#print(\\'\\'.join([int_to_char[value] for value in pattern]))\\n\\n\\n# generate characters\\nfor i in range(1000):\\n    x = np.reshape(pattern, (1, len(pattern), 1))\\n    x = x / float(n_vocab)\\n    prediction = model.predict(x, verbose=0)\\n    index = np.argmax(prediction)\\n    result = int_to_char[index]\\n    seq_in = [int_to_char[value] for value in pattern]\\n    sys.stdout.write(result)\\n    pattern.append(index)\\n    pattern = pattern[1:len(pattern)]\\n#print \"\\nDone.\"\\nprint (\"\".join([int_to_char[value] for value in pattern]))'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "#print(''.join([int_to_char[value] for value in pattern]))\n",
    "\n",
    "\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "#print \"\\nDone.\"\n",
    "print (\"\".join([int_to_char[value] for value in pattern]))\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t sell you that is the world be consul.\n",
      "\n",
      "coriolanus:\n",
      "i will not sell you that is the world be consul\n"
     ]
    }
   ],
   "source": [
    "randomVal = np.random.randint(0, len(dataX)-1)\n",
    "randomStart = dataX[randomVal]\n",
    "for i in range(10000):\n",
    "    x = np.reshape(randomStart, (1, len(randomStart), 1))        \n",
    "    x = x/float(n_vocab)\n",
    "    pred = model.predict(x)\n",
    "    index = np.argmax(pred)\n",
    "    randomStart.append(index)\n",
    "    randomStart = randomStart[1: len(randomStart)]\n",
    "print(\"\".join([int_to_char[value] for value in randomStart]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
